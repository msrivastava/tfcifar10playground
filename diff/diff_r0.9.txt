Only in cifar10_r0.9: BUILD
Only in cifar10_r0.9: README.md
diff mcifar10/__init__.py cifar10_r0.9/__init__.py
21,22c21,22
< from mcifar10 import cifar10
< from mcifar10 import cifar10_input
---
> from tensorflow.models.image.cifar10 import cifar10
> from tensorflow.models.image.cifar10 import cifar10_input
Only in mcifar10: __init__.pyc
diff mcifar10/cifar10.py cifar10_r0.9/cifar10.py
13,14c13
< # limitations under the License.    
< # For NEFESH COMPUTER
---
> # limitations under the License.
48c47
< from mcifar10 import cifar10_input
---
> from tensorflow.models.image.cifar10 import cifar10_input
53c52
< tf.app.flags.DEFINE_integer('batch_size', 64,
---
> tf.app.flags.DEFINE_integer('batch_size', 128,
55c54
< tf.app.flags.DEFINE_string('data_dir', '/tmp/mcifar10_data',
---
> tf.app.flags.DEFINE_string('data_dir', '/tmp/cifar10_data',
63,64c62
< TRAIN_FILE = cifar10_input.TRAIN_FILE
< EVAL_FILE = cifar10_input.EVAL_FILE
---
> 
70c68
< INITIAL_LEARNING_RATE = 0.01 #0.1       # Initial learning rate.
---
> INITIAL_LEARNING_RATE = 0.1       # Initial learning rate.
77,81c75,76
< #DATA_URL = 'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'
< #DATA_URL = 'https://dl.dropboxusercontent.com/s/5ic8b62y7a97aow/Classification_Pi_Noise.zip'
< #DATA_URL = 'https://dl.dropboxusercontent.com/s/3i2da52ktt4l9j0/Classification_Pi_Noise_Nc.zip'
< DATA_URL = cifar10_input.DATA_URL
< DATA_FILE_ROOT = cifar10_input.DATA_FILE_ROOT
---
> DATA_URL = 'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'
> 
153c148
<   data_dir = os.path.join(FLAGS.data_dir, DATA_FILE_ROOT)
---
>   data_dir = os.path.join(FLAGS.data_dir, 'cifar-10-batches-bin')
173c168
<   data_dir = os.path.join(FLAGS.data_dir, DATA_FILE_ROOT)
---
>   data_dir = os.path.join(FLAGS.data_dir, 'cifar-10-batches-bin')
192,193c187
<   # conv1 
< #V1 Measurements: 
---
>   # conv1
224c218
<   pool2 = tf.nn.max_pool(norm2, ksize=[1, 5, 5, 1],
---
>   pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],
367d360
<   import zipfile
382,384c375
<     #tarfile.open(filepath, 'r:gz').extractall(dest_directory)
<     with zipfile.ZipFile(filepath, 'r') as myzip:
< 	  myzip.extractall(dest_directory)
---
>     tarfile.open(filepath, 'r:gz').extractall(dest_directory)
Only in mcifar10: cifar10.pyc
diff mcifar10/cifar10_eval.py cifar10_r0.9/cifar10_eval.py
40d39
< import sys
45c44
< from mcifar10 import cifar10
---
> from tensorflow.models.image.cifar10 import cifar10
49c48
< tf.app.flags.DEFINE_string('eval_dir', '/tmp/mcifar10_eval',
---
> tf.app.flags.DEFINE_string('eval_dir', '/tmp/cifar10_eval',
53c52
< tf.app.flags.DEFINE_string('checkpoint_dir', '/tmp/mcifar10_train',
---
> tf.app.flags.DEFINE_string('checkpoint_dir', '/tmp/cifar10_train',
55c54
< tf.app.flags.DEFINE_integer('eval_interval_secs', 30,
---
> tf.app.flags.DEFINE_integer('eval_interval_secs', 60 * 5,
57c56
< tf.app.flags.DEFINE_integer('num_examples', cifar10.NUM_EXAMPLES_PER_EPOCH_FOR_EVAL,
---
> tf.app.flags.DEFINE_integer('num_examples', 10000,
61,127d59
< def calculate_precision(model_predictions, correct_predictions):
< 	sum_avg = 0
< 	amount = 0
< 	num_predictions = 0
< 	for i in range(len(model_predictions)):
< 		#hits = 0
< 		#false_alarms = 0
< 		if(model_predictions[i] == 0):
< 			sum_avg += 0
< 		else:
< 			sum_avg += (correct_predictions[i]/model_predictions[i])
< 			#num_predictions += model_predictions[i]
< 			#hits += (correct_predictions[i])
< 			#false_alarms += (model_predictions[i]-correct_predictions[i])
< 			#print("Index: "+str(i)+" Hits: "+str(hits)+" False Alarm: "+str(false_alarms))
< 			amount += 1
< 	if(amount == 0):
< 		return 0 
< 	return sum_avg/amount
< 
< 
< def calculate_recall(correct_predictions, needed_predictions):
< 	sum_avg = 0
< 	amount = 0
< 	for i in range(len(correct_predictions)):
< 		hits = 0
< 		misses = 0
< 		if(needed_predictions[i] == 0):
< 			sum_avg += 0
< 		else:
< 			sum_avg += (correct_predictions[i]/needed_predictions[i])
< 			hits += correct_predictions[i]
< 			misses += (needed_predictions[i]-correct_predictions[i])
< 			print("Index: "+str(i)+" Hits: "+str(hits)+" Misses: "+str(misses)+" ")
< 			amount += 1
< 	if(amount == 0):
< 		return 0
< 	return sum_avg/amount
< 
< def calculate_false_positives(incorrect_predictions, needed_predictions):
< 	if (len(incorrect_predictions) == len(needed_predictions)):
< 		print("Yay! LENGHTS MATCH")
< 	sum_avg = 0
< 	amount = 0
< 	for class_index in range(len(incorrect_predictions)):
< 		false_positives = 0
< 		correct_rejects = 0
< 		negative_amt = 0
< 		for i in range(len(needed_predictions)):
< 			if(i != class_index):
< 				negative_amt += needed_predictions[i]
< 		if (incorrect_predictions[class_index] == 0):
< 			print("Index: "+str(class_index)+" False Positives: 0 Correct Rejects: "+str(negative_amt)+" ")
< 			sum_avg += 0
< 			amount += 1
< 		else:
< 			#print(class_index)
< 			sum_avg += (incorrect_predictions[class_index]/negative_amt)
< 			false_positives += incorrect_predictions[class_index]
< 			correct_rejects += (negative_amt - incorrect_predictions[class_index])
< 			#print(incorrect_predictions[class_index])
< 			#print(negative_amt)
< 			print("Index: "+str(class_index)+" False Positives: "+str(false_positives)+" Correct Rejects: "+str(correct_rejects))
< 			amount += 1
< 	if(amount == 0):
< 		return 0
< 	return sum_avg/amount   
130c62
< def eval_once(saver, summary_writer, top_k_op, summary_op, logits, labels, new_top_values_op):
---
> def eval_once(saver, summary_writer, top_k_op, summary_op):
163,166d94
<       new_predicts_for_each_label = [0 for i in range(cifar10.NUM_CLASSES)]
<       new_correct_predicts_for_each_label = [0 for i in range(cifar10.NUM_CLASSES)]
<       new_incorrect_predicts_for_each_label = [0 for i in range(cifar10.NUM_CLASSES)]
<       new_actual_amount_per_label = [0 for i in range(cifar10.NUM_CLASSES)]
169,173c97
<         [actual_labels, new_logits, predictions, new_values, new_indices] = sess.run([labels, logits, top_k_op, new_top_values_op[0], new_top_values_op[1]])
<         #print(actual_labels)
<         #print(predictions)
<         #print("new indices: ")
<         #print(new_indices)  
---
>         predictions = sess.run([top_k_op])
175,183d98
<         for i in range(FLAGS.batch_size):
<         	predict_class = new_indices[i][0]
<         	new_predicts_for_each_label[predict_class] += 1
<         	actual_label = actual_labels[i]
<         	new_actual_amount_per_label[actual_label] += 1
< 	        if(predictions[i]):  #THIS SHOULD ONLY OCCUR WHEN "Class with top value" EQUALS "Actual Class Label"
< 	        	new_correct_predicts_for_each_label[predict_class] += 1
< 	        else:
< 	        	new_incorrect_predicts_for_each_label[predict_class] += 1   	                 
185,198c100,101
<         print(step)
<         print(coord.should_stop())
<       #print(new_predicts_for_each_label)
<       #print(new_correct_predicts_for_each_label) 
<       print("Megha's Precision: ")
<       print(calculate_precision(new_predicts_for_each_label, new_correct_predicts_for_each_label))
<       print("Megha's Recall/ TRUE POSITIVE Rate: ")
<       print(calculate_recall(new_correct_predicts_for_each_label, new_actual_amount_per_label))
<       print("Megha's False Positive Rate: ")
<       print(calculate_false_positives(new_incorrect_predicts_for_each_label, new_actual_amount_per_label))
< 
<       # Compute precision @ 1.  
<       #print(logits[0,:].eval())
<       #print(labels[1].eval())
---
> 
>       # Compute precision @ 1.
222a126
> 
225d128
<     new_top_values_op = tf.nn.top_k(logits)
239c142
<       eval_once(saver, summary_writer, top_k_op, summary_op, logits, labels, new_top_values_op)
---
>       eval_once(saver, summary_writer, top_k_op, summary_op)
diff mcifar10/cifar10_input.py cifar10_r0.9/cifar10_input.py
13,14c13
< # limitations under the License. 
< # Megha: FOR NEFESH COMP
---
> # limitations under the License.
28,29d26
< # DATA SET CONFIGURATION
< 
33c30
< IMAGE_SIZE = 140
---
> IMAGE_SIZE = 24
36,45c33,35
< #DATA_URL = 'https://dl.dropboxusercontent.com/s/5ic8b62y7a97aow/Classification_Pi_Noise.zip'
< DATA_URL = 'https://dl.dropbox.com/s/u1dn6z5j8u79w71/Classification_All_Blur_140v1.zip'
< DATA_FILE_ROOT = DATA_URL.split('/')[-1][0:-4]
< TRAIN_FILE = 'all_train.bin'
< EVAL_FILE = 'all_test13.bin'
< NUM_CLASSES = 101
< NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 1212
< NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 303
< NUM_BATCHES = 2
< 
---
> NUM_CLASSES = 10
> NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000
> NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000
78,79c68,69
<   result.height = IMAGE_SIZE
<   result.width = IMAGE_SIZE
---
>   result.height = 32
>   result.width = 32
159,160c149,150
<   filenames = [os.path.join(data_dir, TRAIN_FILE)
<                for i in xrange(1, NUM_BATCHES)]
---
>   filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i)
>                for i in xrange(1, 6)]
179c169
<   #distorted_image = tf.random_crop(reshaped_image, [height, width, 3])
---
>   distorted_image = tf.random_crop(reshaped_image, [height, width, 3])
182c172
<   #distorted_image = tf.image.random_flip_left_right(distorted_image)
---
>   distorted_image = tf.image.random_flip_left_right(distorted_image)
186c176
<   distorted_image = tf.image.random_brightness(reshaped_image,
---
>   distorted_image = tf.image.random_brightness(distorted_image,
220,221c210,211
<     filenames = [os.path.join(data_dir, TRAIN_FILE)
<                  for i in xrange(1, NUM_BATCHES)]
---
>     filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i)
>                  for i in xrange(1, 6)]
224c214
<     filenames = [os.path.join(data_dir, EVAL_FILE)]
---
>     filenames = [os.path.join(data_dir, 'test_batch.bin')]
Only in mcifar10: cifar10_input.pyc
diff mcifar10/cifar10_input_test.py cifar10_r0.9/cifar10_input_test.py
26c26
< from mcifar10 import cifar10_input
---
> from tensorflow.models.image.cifar10 import cifar10_input
diff mcifar10/cifar10_multi_gpu_train.py cifar10_r0.9/cifar10_multi_gpu_train.py
50c50
< from mcifar10 import cifar10
---
> from tensorflow.models.image.cifar10 import cifar10
54c54
< tf.app.flags.DEFINE_string('train_dir', '/tmp/mcifar10_train',
---
> tf.app.flags.DEFINE_string('train_dir', '/tmp/cifar10_train',
diff mcifar10/cifar10_train.py cifar10_r0.9/cifar10_train.py
13,15c13
< # limitations under the License.     
< 
< # FOR NEFESH COMPUTER
---
> # limitations under the License.
49c47
< from mcifar10 import cifar10
---
> from tensorflow.models.image.cifar10 import cifar10
53c51
< tf.app.flags.DEFINE_string('train_dir', '/tmp/mcifar10_train',
---
> tf.app.flags.DEFINE_string('train_dir', '/tmp/cifar10_train',
56c54
< tf.app.flags.DEFINE_integer('max_steps', 20000,
---
> tf.app.flags.DEFINE_integer('max_steps', 1000000,
